test vcode arch=arm64

function %a(i32) -> i32 {
block0(v0: i32):
    v1 = bitrev v0
    return v1
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: rbit w0, w0
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret

function %a(i64) -> i64 {
block0(v0: i64):
    v1 = bitrev v0
    return v1
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: rbit x0, x0
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret

function %b(i32) -> i32 {
block0(v0: i32):
    v1 = clz v0
    return v1
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: clz w0, w0
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret

function %b(i64) -> i64 {
block0(v0: i64):
    v1 = clz v0
    return v1
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: clz x0, x0
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret

function %c(i32) -> i32 {
block0(v0: i32):
    v1 = cls v0
    return v1
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: cls w0, w0
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret

function %c(i64) -> i64 {
block0(v0: i64):
    v1 = cls v0
    return v1
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: cls x0, x0
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret

function %d(i32) -> i32 {
block0(v0: i32):
    v1 = ctz v0
    return v1
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: rbit w0, w0
; nextln: clz w0, w0
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret

function %d(i64) -> i64 {
block0(v0: i64):
    v1 = ctz v0
    return v1
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: rbit x0, x0
; nextln: clz x0, x0
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret
